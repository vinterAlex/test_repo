name: Create BigQuery Dataset on PR

on:
  pull_request:
    types: [opened, reopened, synchronize]

jobs:
  create-bigquery-dataset:
    runs-on: ubuntu-latest
    steps:
      # Step 1: Check out the code
      - name: Checkout repository
        uses: actions/checkout@v2

      # Step 2: Write Service Account Key to File
      - name: Write service account key to file
        run: echo "${{ secrets.BQ_DROP_SCHEMA_ON_MERGE }}" > /tmp/service-account.json

      # Step 3: Set up Google Cloud credentials
      - name: Set up Google Cloud credentials
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.BQ_DROP_SCHEMA_ON_MERGE }}

      # Step 4: Set up gcloud CLI
      - name: Set up gcloud CLI
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: "alexvspreadsheets"

      # Step 5: Create a BigQuery dataset
      - name: Create BigQuery dataset
        env:
          PROJECT_ID: "alexvspreadsheets"
          DATASET_NAME: "dbt_cloud_pr_${{ github.event.pull_request.number }}_${{ github.run_id }}"
        run: |
          echo "Activating service account..."
          gcloud auth activate-service-account --key-file=/tmp/service-account.json
          
          echo "Creating BigQuery dataset..."
          gcloud bigquery datasets create "${DATASET_NAME}" --project="${PROJECT_ID}" --location=US || echo "Dataset may already exist."
